---
title: 'perturb-seq 数据分析： semiNMF'
date: 2025-06-01
permalink: /posts/2025/05/blog-post-7.md
tags:
  - perturbseq
  - gene program
  - regulatory network
  - semiNMF
---


上一篇讲了oNMF，即每个基因只贡献于一个gene program，那么可以将基因很好的分类。
但是：
* 其假设\\(\mathbf{W}\\)和\\(\mathbf{H}\\)的非负性不符合生物学的实际。
* 其假设gene program之间正交不符合基因多效性

还有一种NMF，限制\\(\mathbf{W}\\)或\\(\mathbf{H}\\)其中一个矩阵非负，另一个矩阵则可以包含负数，称之为semiNMF。我们限制\\(\mathbf{W}\\)矩阵非负，解除\\(\mathbf{H}\\)矩阵的正交假设，可以弥补oNMF方法中的上述缺陷。

## 代码实现

* 数据读取

```python

import numpy as np
import pandas as pd
import scanpy as sc
import sys
#sys.path.append("/ahg/regevdata/projects/Cell2CellCommunication/code/MIMOSCA")

%matplotlib inline
import matplotlib.pyplot as plt

import dspin

sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)
sc.settings.set_figure_params(dpi=200, color_map='viridis')
#sc.logging.print_versions()
import matplotlib
matplotlib.rcParams['pdf.fonttype'] = 42
matplotlib.rcParams['ps.fonttype'] = 42


dir = '/home/yzeng/proj/Perturb_seq/rerun/'
## /home/yzeng/proj/Perturb_seq/rerun/Clean_Counts.h5ad
adata=sc.read(dir+'Clean_Counts.h5ad')
adata.raw = adata


adata.obs['batch_wider'] = 1
df2 = pd.DataFrame(adata.obs[['batch','batch_wider']]).pivot(columns='batch').fillna('0')
for obs_add in df2['batch_wider'].columns:
    obs_n = 'batch' + obs_add
    adata.obs[obs_n] = df2['batch_wider'][obs_add].astype(float)

adata.var['mt'] = adata.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'
sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)
adata.obs


cell_cycle_path = '/home/yzeng/proj/Perturb_seq/yzeng/Perturb_seq_analysis/pertpy_analysis/data/regev_lab_cell_cycle_genes.txt'
cell_cycle_genes = [x.strip() for x in open(cell_cycle_path)]

s_genes = cell_cycle_genes[:43]
g2m_genes = cell_cycle_genes[43:]
print(len(cell_cycle_genes))
cell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]


adata.layers['counts'] = adata.X.copy()

sc.pp.normalize_total(adata,target_sum=1e4)
sc.pp.log1p(adata)

adata.layers['normalized'] = adata.X.copy()

sc.pp.scale(adata,max_value=10)
sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)



adata.X = adata.layers['normalized'].copy()
sc.pp.highly_variable_genes(adata,min_mean=0.0125,max_mean=3,min_disp=0.5,subset=True )

```

* 定义\\(\mathbf{W}\\)非负的semiNMF

```python

from numpy.testing import *
import numpy as np
import logging
import logging.config
import scipy.sparse
import scipy.io as spio
import matplotlib.pyplot as plt
import random

__all__ = ["PyMFBase"]
_EPS = np.finfo(float).eps  # In real case, this eps should be larger.


class PyMFBase:
    """ PyMF base class used in (almost) all matrix factorization methods
    PyMF Base Class. Does nothing useful apart from providing some basic methods. """
    # some small value
    _EPS = _EPS

    def __init__(self, data, num_bases=4, **kwargs):
        """
        """

        def setup_logging():
            # create logger
            self._logger = logging.getLogger("pymf")

            # add ch to logger
            if len(self._logger.handlers) < 1:
                # create console handler and set level to debug
                ch = logging.StreamHandler()
                ch.setLevel(logging.DEBUG)
                # create formatter
                formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

                # add formatter to ch
                ch.setFormatter(formatter)

                self._logger.addHandler(ch)

        setup_logging()

        # set variables
        self.data = data
        self._num_bases = num_bases

        # initialize H and W to random values
        self._data_dimension, self._num_samples = self.data.shape

    def residual(self):
        """ Returns the residual in % of the total amount of data
            Returns: residual (float)
        """
        res = np.sum(np.abs(self.data - np.dot(self.W, self.H)))
        total = 100.0 * res / np.sum(np.abs(self.data))
        return total

    def frobenius_norm(self):
        """ Frobenius norm (||data - WH||) of a data matrix and a low rank approximation given by WH.
            Minimizing the Fnorm ist the most common optimization criterion for matrix factorization methods.
            Returns: frobenius norm: F = ||data - WH||
        """
        # check if W and H exist
        if hasattr(self, 'H') and hasattr(self, 'W'):
            if scipy.sparse.issparse(self.data):
                tmp = self.data[:, :] - (self.W * self.H)
                tmp = tmp.multiply(tmp).sum()
                err = np.sqrt(tmp)
            else:
                err = np.sqrt(np.sum((self.data[:, :] - np.dot(self.W, self.H)) ** 2))
        else:
            err = None

        return err

    def _init_w(self):
        """ Initalize W to random values [0,1].
        """
        # add a small value, otherwise nmf and related methods get into trouble as
        # they have difficulties recovering from zero.
        self.W = np.random.random((self._data_dimension, self._num_bases)) + 0.2 ## 10 ** -4

    def _init_h(self):
        """ Initalize H to random values [0,1].
        """
        self.H = np.random.random((self._num_bases, self._num_samples)) + 10** -4 ## 0.2

    def _update_h(self):
        """ Overwrite for updating H.
        """
        pass

    def _update_w(self):
        """ Overwrite for updating W.
        """
        pass

    def _converged(self, i):
        """
        If the optimization of the approximation is below the machine precision,
        return True.

        Parameters
        ----------
            i   : index of the update step

        Returns
        -------
            converged : boolean
        """
        derr = np.abs(self.ferr[i] - self.ferr[i - 1]) / self._num_samples
        if derr < self._EPS:
            return True
        else:
            return False

    def factorize(self, niter=100, show_progress=False,
                  compute_w=True, compute_h=True, compute_err=True):
        """ Factorize s.t. WH = data

        Parameters
        ----------
        niter : int
                number of iterations.
        show_progress : bool
                print some extra information to stdout.
        compute_h : bool
                iteratively update values for H.
        compute_w : bool
                iteratively update values for W.
        compute_err : bool
                compute Frobenius norm |data-WH| after each update and store
                it to .ferr[k].

        Updated Values
        --------------
        .W : updated values for W.
        .H : updated values for H.
        .ferr : Frobenius norm |data-WH| for each iteration.
        """

        if show_progress:
            self._logger.setLevel(logging.INFO)
        else:
            self._logger.setLevel(logging.ERROR)

            # create W and H if they don't already exist
        # -> any custom initialization to W,H should be done before
        if not hasattr(self, 'W') and compute_w:
            self._init_w()

        if not hasattr(self, 'H') and compute_h:
            self._init_h()

            # Computation of the error can take quite long for large matrices,
        # thus we make it optional.
        if compute_err:
            self.ferr = np.zeros(niter)

        for i in range(niter):
            if compute_w:
                self._update_w()

            if compute_h:
                self._update_h()

            if compute_err:
                self.ferr[i] = self.frobenius_norm()
                self._logger.info('FN: %s (%s/%s)' % (self.ferr[i], i + 1, niter))
            else:
                self._logger.info('Iteration: (%s/%s)' % (i + 1, niter))

            # check if the err is not changing anymore
            if i > 1 and compute_err:
                if self._converged(i):
                    # adjust the error measure
                    self.ferr = self.ferr[:i]
                    break


class SNMF(PyMFBase):
    """
    SNMF(data, num_bases=4)

    Semi Non-negative Matrix Factorization. Factorize a data matrix into two
    matrices s.t. F = | data - W*H | is minimal. For this modified version,
    only W is constrained to non-negativity.

    Parameters
    ----------
    data : array_like, shape (_data_dimension, _num_samples)
        the input data
    num_bases: int, optional
        Number of bases to compute (column rank of W and row rank of H).
        4 (default)

    Attributes
    ----------
    W : "data_dimension x num_bases" matrix of basis vectors (non-negative)
    H : "num bases x num_samples" matrix of coefficients (unconstrained)
    ferr : frobenius norm (after calling .factorize())

    The result is a set of non-negative basis vectors W, s.t. data = W * H.
    """

    def _update_w(self):
        def separate_positive(m):
            return (np.abs(m) + m) / 2.0

        def separate_negative(m):
            return (np.abs(m) - m) / 2.0

        # Compute terms for W update
        DH = np.dot(self.data, self.H.T)        # Data times H transpose
        HH = np.dot(self.H, self.H.T)           # H times H transpose
        
        # Separate positive and negative components
        DH_pos = separate_positive(DH)
        DH_neg = separate_negative(DH)
        HH_pos = separate_positive(HH)
        HH_neg = separate_negative(HH)
        
        # Numerator and denominator for multiplicative update
        numerator = DH_pos + np.dot(self.W, HH_neg)
        denominator = DH_neg + np.dot(self.W, HH_pos) + 10**-9
        
        # Update W using multiplicative rule (ensures non-negativity)
        self.W *= numerator / denominator

    def _update_h(self):
        # Solve for H using least squares (unconstrained)
        # H = (W^T W)^{-1} W^T data
        WtW = np.dot(self.W.T, self.W)
        Wt_data = np.dot(self.W.T, self.data)
        self.H = np.linalg.solve(WtW, Wt_data)

```


* 对adata的normalized表达矩阵进行semiNMF

```python

num_factor=50
X = adata.layers['normalized'].todense().copy()
for a in range(5,50,5):
    mdl = SNMF(X, num_bases=a)
    # nmf forms a cone in the input space, but it is unlikely to hit the
    # cone exactly.
    mdl.factorize(niter=100,compute_err=False)
    #residual_y = mdl.ferr
    #plot_x = len(residual_y)
    #print("ferr: ", residual_y, "\n")
    #print(plot_x)
    #plt.plot(residual_y)
#plt.ylabel('residual value by iteration')
#plt.show()
plt.imshow(mdl.H, aspect='auto')
plt.show()
# the reconstruction quality should be close to perfect
#rec = mdl.frobenius_norm()
#assert_array_almost_equal(0.0, rec, decimal=1)
# and H is not allowed to have <0 values
l = np.where(mdl.H < 0)[0]
assert(len(l) == 0)
print("Basis Vector F: ", mdl.W, "\n")
print("Coefficients Matrix G: ", mdl.H, "\n")
#print("Residual Value: ", rec)
```
![semiNMF_gene_program_heatmap.png](https://whuyanzeng.github.io/images/semiNMF_gene_program_heatmap.png)



* 查看分解的\\(\mathbf{W}\\)和\\(\mathbf{H}\\)

```python

plt.imshow(mdl.W, aspect='auto')
plt.show()
pd_W = pd.DataFrame(mdl.W, index=adata.obs.index.values )
pd_W['gene.compact'] = adata.obs['gene.compact']
pd_W = pd_W.sort_values(by='gene.compact')
y_label_dict= {}
y_label_list=[]
cur = 0
for i in pd_W['gene.compact']:
    cur += 1
    y_label_dict[i] = cur
y_label_pd = pd_W['gene.compact']
pd_W = pd_W.drop(columns=['gene.compact'])
import seaborn as sns

#ax  = sns.clustermap(pd_W ,  row_cluster=False,  yticklabels=False , cmap='bwr')
pd_W.index = y_label_pd
ax = sns.heatmap(pd_W, yticklabels =False , cmap='RdBu_r', vmin=-0.03,vmax=0.03)
for gene in y_label_dict.keys():
    ax.axhline(y=y_label_dict[gene], color='k',linewidth=0.2)
sns.clustermap(mdl.H ,  row_cluster=False,  yticklabels=False , cmap='RdBu_r', vmin=-20,vmax=20)

```
![semiNMF_program_cell_heatmap.png](https://whuyanzeng.github.io/images/semiNMF_program_cell_heatmap.png)
![semiNMF_gene_program_clusteredheatmap.png](https://whuyanzeng.github.io/images/semiNMF_gene_program_clusteredheatmap.png)



* 检验program的显著性，并绘制箱线图

```python

import scanpy as sc
import numpy as np
import pandas as pd
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import seaborn as sns
import matplotlib.pyplot as plt
import gseapy as gp

adata.obsm['X_semi_nmf'] = mdl.W
adata.varm['H_matrix'] = mdl.H.T
# 提取分类变量和W矩阵
adata.obs['gene_compact'] = adata.obs['gene.compact']
groups = adata.obs['gene_compact']
W = pd.DataFrame(adata.obsm['X_semi_nmf'], 
                index=adata.obs_names, 
                columns=[f"Factor_{i}" for i in range(adata.obsm['X_semi_nmf'].shape[1])])

# 合并分组信息
W_grouped = W.join(groups)

# 对每个因子进行ANOVA分析
anova_results = []
for factor in W.columns:
    model = ols(f'{factor} ~ C(gene_compact)', data=W_grouped).fit()
    anova_table = sm.stats.anova_lm(model, typ=2)
    anova_results.append({
        'Factor': factor,
        'F-value': anova_table['F'][0],
        'p-value': anova_table['PR(>F)'][0]
    })

# 转换为DataFrame并校正p值
anova_df = pd.DataFrame(anova_results)
anova_df['q-value'] = sm.stats.multipletests(anova_df['p-value'], method='fdr_bh')[1]

# 筛选显著因子
significant_factors = anova_df[anova_df['q-value'] < 0.05]
print("Significant factors across groups:")
print(significant_factors)


# 选择最显著的25个因子
top_factors = significant_factors.nsmallest(25, 'q-value')['Factor'].values

# 绘制箱型图
#plt.rcParams['figsize']=(15, 6)
for  factor in top_factors :
    fig, ax = plt.subplots(1, 1,figsize=(15,6))
    sns.boxplot(x='gene_compact', y=factor, data=W_grouped, ax=ax, palette="Set3")
    ax.set_title(f"{factor}\n(q={significant_factors.loc[significant_factors['Factor']==factor, 'q-value'].values[0]:.2e})")
    #ax.tick_params(axis='x', rotation=45 )
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90,ha='center')
plt.tight_layout()
plt.show()
```
![例子boxPlot(program14)](https://whuyanzeng.github.io/images/semiNMF_KO_program_boxplot.png)

* 进行GO富集，绘制富集dotplot

```python

# 假设H矩阵存储为 (factors x genes)
H = pd.DataFrame(adata.varm['H_matrix'].T, 
                columns=adata.var_names, 
                index=[f"Factor_{i}" for i in range(adata.varm['H_matrix'].shape[1])])

# 获取每个因子的Top 100基因
top_genes_per_factor = {}
for factor in H.index:
    sorted_genes = H.loc[factor].sort_values(ascending=False)
    top_genes_per_factor[factor] = sorted_genes.index[:100].tolist()
# 导入所需库
from gseapy import enrichr
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 设置分析参数
top_genes = 100  # 每个因子取Top基因数
adj_pval_cutoff = 0.05  # 显著性阈值

# 定义要使用的基因集
gene_sets = [
    'GO_Biological_Process_2021',  # GOBP
  #  'MSigDB_Hallmark_2020'               # MSigDB Hallmark
]

# 初始化结果存储
enrich_results = {}

# 对每个因子进行富集分析
for factor, genes in top_genes_per_factor.items():
    # 执行Enrichr分析
    enr = enrichr(gene_list=genes[:top_genes],
                  gene_sets=gene_sets,
                  organism='Human',  # 根据数据更改为 Mouse 或其它
                  cutoff=0.5)
    
    # 保存结果（合并两个基因集的结果）
    df = enr.results
    df['GeneSet_Type'] = df['Gene_set'].apply(
        lambda x: 'GOBP' if 'GO_Biological' in x else 'Hallmark')
    enrich_results[factor] = df

# 合并所有结果
all_enrich = pd.concat(
    {k: df.assign(Factor=k) for k, df in enrich_results.items()},
    axis=0
).reset_index(drop=True)

# 筛选显著结果
significant = all_enrich[all_enrich['Adjusted P-value'] < adj_pval_cutoff]

# 按基因集类型拆分结果
go_bp = significant[significant['GeneSet_Type'] == 'GOBP']
hallmark = significant[significant['GeneSet_Type'] == 'Hallmark']
# 选择每个因子最显著的通路
significant_pathways = go_bp
top_pathways = significant_pathways.sort_values('Adjusted P-value').groupby('Factor').head(3)

# 绘制dotplot
plt.figure(figsize=(12, 13))
sns.scatterplot(data=top_pathways, 
                x='Factor', 
                y='Term', 
                size=-np.log10(top_pathways['Adjusted P-value']), 
                hue='Combined Score', 
                palette='viridis')
plt.title("Top Enriched Pathways per Factor")
plt.xlabel("")
plt.ylabel("")
plt.xticks(rotation=45, ha='right')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
```
![semiNMF_program_GO_dotplot.png](https://whuyanzeng.github.io/images/semiNMF_program_GO_dotplot.png)


* 保存结果

```python

# 保存统计结果
with pd.ExcelWriter('semiNMF_analysis_results.xlsx') as writer:
    anova_df.to_excel(writer, sheet_name='W_ANOVA')
    significant_factors.to_excel(writer, sheet_name='Significant Factors')
    all_enrich.to_excel(writer, sheet_name='Pathway Enrichment')
    top_pathways.to_excel(writer, sheet_name='Top Pathways')

# 保存基因列表
for factor, genes in top_genes_per_factor.items():
    pd.Series(genes, name=f"{factor}_top_genes").to_csv(
        f"{factor}_top100_genes.csv", index=False)
```
